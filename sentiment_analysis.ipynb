{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import spacy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in csv as DF.\n",
    "df = pd.read_csv(\"amazon_product_reviews.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the necessary columns for sentiment analysis.\n",
    "cleaned = df[['reviews.text', 'reviews.title']]\n",
    "cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for any null values.\n",
    "cleaned.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the English language model.\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatize text and filter out punctuation and stop words.\n",
    "cleaned['processed.text'] = cleaned['reviews.text'].apply(lambda sample: ' '.join([token.lemma_ for token in nlp(sample.lower().strip()) if not token.is_punct and not token.is_stop]))\n",
    "cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for further analysis and add textblob.\n",
    "# Extension to spaCy pipeline.\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "from collections import defaultdict\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "nlp.add_pipe('spacytextblob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate polarity and subjectivity of a text.\n",
    "def polarity(sample):\n",
    "\n",
    "    doc = nlp(sample)\n",
    "    \n",
    "    polarity_value = doc._.blob.polarity\n",
    "\n",
    "    subjectivity_value = doc._.blob.subjectivity\n",
    "    \n",
    "    return sample, polarity_value, subjectivity_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise dictionaries to count positive and negative words.\n",
    "positive_words = defaultdict(int)\n",
    "negative_words = defaultdict(int)\n",
    "\n",
    "# Iterate over processed text samples to determine sentiment.\n",
    "for item in cleaned['processed.text'].values:\n",
    "\n",
    "    sample, polarity_score, subjectivity_score = polarity(item)\n",
    "\n",
    "    if polarity_score > 0:\n",
    "        sentiment = \"Positive\"\n",
    "        positive_words[item] += 1\n",
    "\n",
    "    elif polarity_score < 0:\n",
    "        sentiment = \"Negative\"\n",
    "        negative_words[item] += 1\n",
    "    \n",
    "    else:\n",
    "        sentiment = \"Neutral\"\n",
    "\n",
    "    print(f\"Review: {sample}\\nPolarity score: {polarity_score}\\nSentiment: {sentiment}\\nSubjectivity: {subjectivity_score}\\n\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word clouds for positive and negative words.\n",
    "pos_wordcloud = WordCloud(width=400, height=200, background_color ='white').generate_from_frequencies(positive_words)\n",
    "neg_wordcloud = WordCloud(width=400, height=200, background_color ='white').generate_from_frequencies(negative_words)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "ax[0].imshow(pos_wordcloud, interpolation='bilinear')\n",
    "ax[0].set_title('Positive Words')\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(neg_wordcloud, interpolation='bilinear')\n",
    "ax[1].set_title('Negative Words')\n",
    "ax[1].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate similarity between two reviews.\n",
    "def review_similarity(review_1, review_2):\n",
    "    \n",
    "    return nlp(review_1).similarity(nlp(review_2))\n",
    "\n",
    "# Select two reviews from the cleaned DataFrame.\n",
    "review_1 = cleaned[\"processed.text\"][0]\n",
    "review_2 = cleaned[\"processed.text\"][1]\n",
    "\n",
    "# Calculate the similarity between the selected reviews.\n",
    "similarity_score = review_similarity(review_1, review_2)\n",
    "\n",
    "print(f\"The similarity between the two reviews is: {similarity_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
